{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7615f2-a95b-417d-a38c-672fd0ca0f61",
   "metadata": {},
   "source": [
    "# Torch MC PILCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a99e72-15d1-46a4-b5f9-aeafc6ec64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0114da-b001-4891-880a-f542798758c3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f588d30c-2a9a-4c75-9f5f-bb8110142d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from tensordict import TensorDict\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import RandomPolicy\n",
    "from torchrl.data import ReplayBuffer\n",
    "from torchrl.data import LazyTensorStorage\n",
    "from torch.func import vmap, functional_call\n",
    "\n",
    "from torch_pilco.model_learning.dynamical_models import (\n",
    "    DynamicalModel,\n",
    "    fit,\n",
    "    data_to_gp_input,\n",
    "    data_to_policy_input\n",
    ")\n",
    "from torch_pilco.policy_learning.controllers import RandomExploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd47fe00-5a92-4bc3-9c1c-bf9083aadf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from torch.func import vmap, functional_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7237f276-91a7-45e2-9b51-93cfb66ac71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cols = mpl.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8aa24-0aae-4d28-b858-ecf6c0f403f7",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfa505c-465d-444b-8f35-49dd47f53025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pendulum_training_data(\n",
    "    data_tensordict: TensorDict,\n",
    " ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    return data_tensordict['observation'].float(), data_tensordict['action'].float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69addce-09c9-44cd-a5b0-a3005182c5b3",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd222c5f-33ad-4658-b202-e6c8efab016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "frames_per_batch = 100\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")\n",
    "random_policy = RandomPolicy(env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1263649a-1cd4-4bc5-9c5a-334092717b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_memory: int = 2\n",
    "control_memory: int = 1\n",
    "queue_size = 1 + max(control_memory, position_memory)\n",
    "num_particles = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82ae524-ac53-48b0-994d-1af91d0741a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_policy_input_closure = functools.partial(data_to_policy_input, position_memory=position_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf51fd0c-d663-4ee9-8faa-7f0f087928e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_gp_input_closure = functools.partial(data_to_gp_input, control_memory=control_memory, position_memory=position_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c8e4dd-8626-421f-89ea-1d9e449edb94",
   "metadata": {},
   "source": [
    "## Generate initial experimenal data from environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d50ded7f-e90b-417b-b5bc-9882752ed402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random trajectory from the environment\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy=random_policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=frames_per_batch,\n",
    ")\n",
    "# Now determine how many frames are stacked for the dynamical model input:\n",
    "\n",
    "replay_buffer = ReplayBuffer(storage=LazyTensorStorage(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce91985-7ac2-4b4b-8787-72c483e30209",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10850e87-852d-49ba-a382-98ad14ce7362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load src/torch_pilco/pendulum.py\n",
    "for data in collector:\n",
    "    # convert the tensordict from collector to a version\n",
    "    # suitable for dynamical model\n",
    "    replay_buffer.extend(data)\n",
    "    states, actions = build_pendulum_training_data(data)\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\n",
    "        num_tasks=states.shape[1]\n",
    "    )\n",
    "    model = DynamicalModel(\n",
    "        states,\n",
    "        actions,\n",
    "        likelihood,\n",
    "        position_memory=position_memory,\n",
    "        control_memory=control_memory,\n",
    "    )\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    fit(model, likelihood, print_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8b70134-4988-431d-a294-8ec577a69099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_pilco.policy_learning.rollout import policy_rollout\n",
    "from torch_pilco.rewards import pendulum_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adc0155d-ca44-4b73-83c7-3aedf637f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pendulum_cost(\n",
    "    states: torch.Tensor,\n",
    "    actions: torch.Tensor,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Replicated Cost function from gymnasium:\n",
    "        -(theta**2 + 0.1*theta_dt**2 + 0.001*torque**2)\n",
    "    but we minimize it, so we return the negation.\n",
    "    \"\"\"\n",
    "\n",
    "    x = states[0]\n",
    "    y = states[1]\n",
    "    angle_velocity = states[2]\n",
    "    torque = actions[0]\n",
    "    theta = torch.atan2(y, x)\n",
    "\n",
    "    return (\n",
    "        torch.square(theta) +\n",
    "        0.1*torch.square(angle_velocity) +\n",
    "        0.001*torch.square(torque)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a91c2ff9-a073-47c6-98e0-e9eab4b13796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3]), torch.Size([100, 1]), torch.Size([100]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape, actions.shape, torch.vmap(pendulum_cost, in_dims=(0,0))(states,actions).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1178a-cab5-4c52-9290-f1c592a1d0b1",
   "metadata": {},
   "source": [
    "### Rollout\n",
    "To do rollout, we:\n",
    "1. sample a random draw from our current replay buffer\n",
    "2. convert the replay buffer sample to a model input\n",
    "3. sample from the dynamical model `num_particles` times\n",
    "4. updates states\n",
    "5. generate actions for each particle\n",
    "   1. initially this will be random\n",
    "   2. after the first iteration, will use the learnt policy\n",
    "6. update running actions for each particle\n",
    "7. convert the running state/action to a model input for each particle\n",
    "8. sample from they dynamical model `1` time for each particle\n",
    "9. repeat steps 4-7 until number of rollout steps is exausted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b35cb2f-a872-4d78-9564-04828302aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = RandomExploration(1,1,True,2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f0feab5-b448-4f2b-b4da-e4a8afcd5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an initial condition for rollout\n",
    "# 1. sample a random draw from current replay buffer\n",
    "replay_buffer_sample = replay_buffer.sample(queue_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbeb7515-fa73-4bf0-8a33-46f014a115c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. convert the replay buffer sample to model input\n",
    "initial_states, initial_actions = build_pendulum_training_data(replay_buffer_sample)\n",
    "model_input = data_to_gp_input(initial_states, initial_actions, control_memory, position_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27396000-93f9-4f4a-9861-74af1b2dfc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. sample from the dynamical model `num_particles` times\n",
    "# Create the posterior:\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    posterior = model(model_input)\n",
    "next_states = posterior.sample(sample_shape=torch.Size([num_particles]))\n",
    "# Now inflate running_states (and running_actions) for each particle\n",
    "running_states = torch.tile(initial_states,(num_particles,1,1))\n",
    "running_actions = torch.tile(initial_actions,(num_particles,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "960a31a8-8c05-4731-9e02-77b5e446645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update running_states\n",
    "running_states = update_states(next_states, running_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6a2e55c-d35e-4cc1-a8a0-b424a6108432",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpolicy_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrunning_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrunning_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpendulum_cost\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/src/torch_pilco/policy_learning/rollout.py:92\u001b[39m, in \u001b[36mpolicy_rollout\u001b[39m\u001b[34m(policy, init_states, init_actions, model, obj_func)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpolicy_rollout\u001b[39m(\n\u001b[32m     85\u001b[39m     policy: Policy,\n\u001b[32m     86\u001b[39m     init_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     obj_func: Callable[[torch.Tensor, torch.Tensor], \u001b[38;5;28mfloat\u001b[39m],\n\u001b[32m     90\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     91\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Just return the mean of the policy rollout.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     mu, _ = \u001b[43mpolicy_rollout_with_std\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mu\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:39\u001b[39m, in \u001b[36mpolicy_rollout_with_std\u001b[39m\u001b[34m(policy, init_states, init_actions, model, obj_func)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:30\u001b[39m, in \u001b[36mone_rollout_step\u001b[39m\u001b[34m(running_states, running_actions)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/apis.py:202\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/vmap.py:334\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    324\u001b[39m         func,\n\u001b[32m    325\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         **kwargs,\n\u001b[32m    331\u001b[39m     )\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/_functorch/vmap.py:484\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    481\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    482\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    483\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mpendulum_cost\u001b[39m\u001b[34m(states, actions)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03mReplicated Cost function from gymnasium:\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    -(theta**2 + 0.1*theta_dt**2 + 0.001*torque**2)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03mbut we minimize it, so we return the negation.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m x = states[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m y = \u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m angle_velocity = states[\u001b[32m2\u001b[39m]\n\u001b[32m     14\u001b[39m torque = actions[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "policy_rollout(policy,running_states,running_actions,model,pendulum_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db4d9763-5340-46cc-a29b-50dc548118f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate actions for each particle\n",
    "action_inputs = torch.vmap(data_to_policy_input_closure, in_dims=0)(running_states)\n",
    "next_actions = torch.vmap(policy, in_dims=0)(action_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b7f0f11-bb52-488c-8ea0-e60a89b30e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_actions = update_actions(next_actions, running_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc418c29-f052-45ea-8658-b5e1deedbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = vmap(data_to_gp_input_closure,in_dims=(0,0))(running_states,running_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db33b156-081d-4274-9401-ea7f9eabd85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1, 11])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a9d96-c16c-4361-bf5e-0adbb6c14aad",
   "metadata": {},
   "source": [
    "### Should vmap the following using ensembling\n",
    "like [here](https://docs.pytorch.org/tutorials/intermediate/ensembling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1475e067-4bcc-4535-9d1c-c60fc9d65c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    posteriors = [model(model_input[i,:,:]) for i in range(num_particles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c76345e9-6289-470e-801b-2238defb3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_samples = [posteriors[i].sample() for i in range(num_particles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19e3ba9c-3940-4c7b-905f-d2183ad19c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states = torch.cat(next_samples).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e689251-3c0e-443e-b16c-82bfa282fdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42d7a8ba-04ff-4ac8-aad5-5806cb34c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update running_states\n",
    "running_states = update_states(next_states, running_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b14a4ebe-0066-4948-bd80-f8a061d117d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate actions for each particle\n",
    "action_inputs = torch.vmap(data_to_policy_input_closure, in_dims=0)(running_states)\n",
    "next_actions = torch.vmap(policy, in_dims=0)(action_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ce62e70-ff13-41f8-8fa0-574de0f1da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_actions = update_actions(next_actions, running_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f11d0ce-896f-4556-b2aa-658e10245bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = vmap(data_to_gp_input_closure,in_dims=(0,0))(running_states,running_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a79a161-f7d2-404b-9475-4ab50d8b8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    posteriors = [model(model_input[i,:,:]) for i in range(num_particles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e03ae989-2e82-42e2-971a-2d91774f8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_samples = [posteriors[i].sample() for i in range(num_particles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56a9a6ea-dbff-4b8f-9a84-f0ee202f53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_states = torch.cat(next_samples).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b9fe92b-e8b2-4c45-9458-7299a5afddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 1, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f415af27-31ff-4e82-8f21-014c9476b59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_pilco.model_learning.dynamical_models.DynamicalModel"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f598d0-3ac0-4d92-9a4e-419db2c65550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
