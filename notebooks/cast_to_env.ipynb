{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfc9a1d-1947-43b8-9baf-dc69ab78e17b",
   "metadata": {},
   "source": [
    "# Convert the fitted GPyTorch model to a TorchRL Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b547463-c093-4df6-b0ca-9e1a91e06333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57624252-d53d-455b-9b64-d3e3f9a37a07",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237da177-1db4-4005-8d86-f3546a2ad787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from tensordict import TensorDict\n",
    "import torchopt\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import RandomPolicy\n",
    "from torchrl.data import ReplayBuffer\n",
    "from torchrl.data import LazyTensorStorage\n",
    "\n",
    "from torch_pilco.model_learning.dynamical_models import (\n",
    "    DynamicalModel,\n",
    "    fit,\n",
    ")\n",
    "from torch_pilco.policy_learning.rbf_layer import RBFLayer\n",
    "from torch_pilco.rewards import pendulum_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80218de1-d328-44aa-828d-d213b688a7f3",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dd7fb89-0441-4d55-a1f9-ce31b70229f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pendulum_training_data(\n",
    "    data_tensordict: TensorDict,\n",
    " ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    return data_tensordict['observation'].float(), data_tensordict['action'].float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c1994-58de-44c1-822d-e1eb55240b0e",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8ad265-c732-476e-ac98-544a4d530573",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "frames_per_batch = 100\n",
    "\n",
    "env = GymEnv(\"Pendulum-v1\")\n",
    "random_policy = RandomPolicy(env.action_spec)\n",
    "action_dim = env.action_space.shape[0]\n",
    "x = env.reset()\n",
    "state_dim = x['observation'].shape[0]\n",
    "\n",
    "num_particles = 400\n",
    "num_basis = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956420e9-43f9-4841-a41f-3d8df9e952b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_policy = RBFLayer(\n",
    "    state_dim,\n",
    "    num_basis,\n",
    "    action_dim,\n",
    "    u_max=env.action_space.high[0],\n",
    ") \n",
    "batched_policy = torch.vmap(control_policy, in_dims=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c542d0f-3791-42a3-b09d-3392c1eafb36",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2388a92-0d21-4a09-b7cf-d34e1084356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random trajectory from the environment\n",
    "# Should create about 5-8 trajectories then stitch them together\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy=random_policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=frames_per_batch,\n",
    ")\n",
    "# Now determine how many frames are stacked for the dynamical model input:\n",
    "\n",
    "replay_buffer = ReplayBuffer(storage=LazyTensorStorage(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389147de-0f3a-4537-be7d-e8db70520324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now grab some data and fit the GP\n",
    "for data in collector:\n",
    "    # convert the tensordict from collector to a version\n",
    "    # suitable for dynamical model\n",
    "    replay_buffer.extend(data)\n",
    "    states, actions = build_pendulum_training_data(data)\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\n",
    "        num_tasks=states.shape[1]\n",
    "    )\n",
    "    model = DynamicalModel(\n",
    "        states,\n",
    "        actions,\n",
    "        likelihood,\n",
    "    )\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    fit(model, likelihood, print_loss = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c5fec-e2ae-409d-8138-a6648842d78a",
   "metadata": {},
   "source": [
    "## Convert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6e26bbf-2a13-4c9a-b3cf-9974d606fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.utils import check_env_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0efa3f6b-ed03-41a8-8357-0934d472e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_pilco.policy_learning.rollout import GPyTorchEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e8450c-31a9-4af9-bdbe-e44a1dbb485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (assuming you have a fitted GPyTorch model named 'fitted_gp_model'):\n",
    "gp_env = GPyTorchEnv(model,env,pendulum_cost,replay_buffer,batch_size=(num_particles,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b291a96c-a6a5-41b7-811f-96aa4059b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2025-12-17 15:38:31,812 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(gp_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd255282-9550-4ce1-ac72-c1c63f3fb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7729a245-78ac-410f-b7fc-3b62fda63da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.nn import TensorDictModule\n",
    "policy = TensorDictModule(\n",
    "    batched_policy,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0362bfbd-ec1e-44fb-b2ab-2ba8dbe9588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(control_policy.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17377498-f4f3-4113-8a77-9085a05de8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b6fc943-95c7-43ee-a60c-f118bb5b4116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward:  114.2512, last reward:  3.3466, gradient norm:  7.887e-05: 100%|██████████████████████████████████████████████| 50/50 [12:23<00:00, 14.86s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = num_particles\n",
    "N = 20000\n",
    "pbar = tqdm.tqdm(range(N // batch_size))        # unsqueeze states\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, N)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "for _ in pbar:\n",
    "    rollout = gp_env.rollout(35, control_policy)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean(dim=0).sum()\n",
    "    traj_return.backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(control_policy.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean(dim=0).item())\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a58a19-3048-4e1b-9c2f-11a1edcbce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did control policy change?  or just policy?  what about batched_policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ea00552-927b-4907-9856-13974f798407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m      policy(*args, **kwargs)\n",
       "\u001b[31mType:\u001b[39m           TensorDictModule\n",
       "\u001b[31mString form:\u001b[39m   \n",
       "TensorDictModule(\n",
       "    module=<function vmap.<locals>.wrapped at 0x7fc023341440>,\n",
       "    device=cpu,\n",
       "    in_keys=['observation'],\n",
       "    out_keys=['action'])\n",
       "\u001b[31mFile:\u001b[39m           ~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/common.py\n",
       "\u001b[31mDocstring:\u001b[39m     \n",
       "A TensorDictModule, is a python wrapper around a :obj:`nn.Module` that reads and writes to a TensorDict.\n",
       "\n",
       "Args:\n",
       "    module (Callable[[Any], Any]): a callable, typically a :class:`torch.nn.Module`,\n",
       "        used to map the input to the output parameter space. Its forward method\n",
       "        can return a single tensor, a tuple of tensors or even a dictionary.\n",
       "        In the latter case, the output keys of the :class:`TensorDictModule`\n",
       "        will be used to populate the output tensordict (ie. the keys present\n",
       "        in ``out_keys`` should be present in the dictionary returned by the\n",
       "        ``module`` forward method).\n",
       "    in_keys (iterable of NestedKeys, Dict[NestedStr, str]): keys to be read\n",
       "        from input tensordict and passed to the module. If it\n",
       "        contains more than one element, the values will be passed in the\n",
       "        order given by the in_keys iterable.\n",
       "        If ``in_keys`` is a dictionary, its keys must correspond to the key\n",
       "        to be read in the tensordict and its values must match the name of\n",
       "        the keyword argument in the function signature. If `out_to_in_map` is ``True``,\n",
       "        the mapping gets inverted so that the keys correspond to the keyword\n",
       "        arguments in the function signature.\n",
       "    out_keys (iterable of str): keys to be written to the input tensordict. The length of out_keys must match the\n",
       "        number of tensors returned by the embedded module. Using \"_\" as a key avoid writing tensor to output.\n",
       "\n",
       "Keyword Args:\n",
       "    out_to_in_map (bool, optional): if ``True`` (default), `in_keys` is read as if the keys are the arguments keys of\n",
       "        the :meth:`~.forward` method and the values are the keys in the input :class:`~tensordict.TensorDict`. If\n",
       "        ``False``, keys are considered to be the input keys and values the method's arguments keys.\n",
       "    inplace (bool or string, optional): if ``True`` (default), the output of the module are written in the tensordict\n",
       "        provided to the :meth:`~.forward` method. If ``False``, a new :class:`~tensordict.TensorDict` with and empty\n",
       "        batch-size and no device is created. if ``\"empty\"``, :meth:`~tensordict.TensorDict.empty` will be used to\n",
       "        create the output tensordict.\n",
       "\n",
       "        .. note::\n",
       "            If ``inplace=False`` and the tensordict passed to the module is another\n",
       "            :class:`~tensordict.TensorDictBase` subclass than :class:`~tensordict.TensorDict`, the output will still\n",
       "            be a :class:`~tensordict.TensorDict` instance. Its batch-size will be empty, and it will have no device.\n",
       "            Set to ``\"empty\"`` to get the same :class:`~tensordict.TensorDictBase` subtype, an identical batch-size\n",
       "            and device. Use ``tensordict_out`` at runtime (see below) to have a more fine-grained control over the\n",
       "            output.\n",
       "\n",
       "        .. note::\n",
       "            If ``inplace=False`` and a `tensordict_out` is passed to the :meth:`~.forward` method,\n",
       "            the ``tensordict_out`` will prevail. This is the way one can get a tensordict_out taensordict passed to the module is another\n",
       "            :class:`~tensordict.TensorDictBase` subclass than :class:`~tensordict.TensorDict`, the output will still\n",
       "            be a :class:`~tensordict.TensorDict` instance.\n",
       "\n",
       "    method (str, optional): the method to be called in the module, if any. Defaults to `__call__`.\n",
       "    method_kwargs (Dict[str, Any], optional): additional keyword arguments to be passed to the module's method being called.\n",
       "    strict (bool, optional): if ``True``, the module will raise an exception if any of the inputs is missing from\n",
       "        the input tensordict. Otherwise, a `None` value will be used as placeholder. Defaults to ``False``.\n",
       "    get_kwargs (dict[str, Any], optional): additional keyword arguments to be passed to the :meth:`~tensordict.TensorDictBase.get`\n",
       "        method. This is particularily useful when dealing with ragged tensors (see :meth:`~tensordict.LazyStackedTensorDict.get`).\n",
       "        Defaults to ``{}``.\n",
       "\n",
       "Embedding a neural network in a TensorDictModule only requires to specify the input\n",
       "and output keys. TensorDictModule support functional and regular :obj:`nn.Module`\n",
       "objects. In the functional case, the 'params' (and 'buffers') keyword argument must\n",
       "be specified:\n",
       "\n",
       "Examples:\n",
       "    >>> from tensordict import TensorDict\n",
       "    >>> # one can wrap regular nn.Module\n",
       "    >>> module = TensorDictModule(nn.Transformer(128), in_keys=[\"input\", \"tgt\"], out_keys=[\"out\"])\n",
       "    >>> input = torch.ones(2, 3, 128)\n",
       "    >>> tgt = torch.zeros(2, 3, 128)\n",
       "    >>> data = TensorDict({\"input\": input, \"tgt\": tgt}, batch_size=[2, 3])\n",
       "    >>> data = module(data)\n",
       "    >>> print(data)\n",
       "    TensorDict(\n",
       "        fields={\n",
       "            input: Tensor(shape=torch.Size([2, 3, 128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "            out: Tensor(shape=torch.Size([2, 3, 128]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "            tgt: Tensor(shape=torch.Size([2, 3, 128]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "        batch_size=torch.Size([2, 3]),\n",
       "        device=None,\n",
       "        is_shared=False)\n",
       "\n",
       "We can also pass directly the tensors\n",
       "\n",
       "Examples:\n",
       "    >>> out = module(input, tgt)\n",
       "    >>> assert out.shape == input.shape\n",
       "    >>> # we can also wrap regular functions\n",
       "    >>> module = TensorDictModule(lambda x: (x-1, x+1), in_keys=[(\"input\", \"x\")], out_keys=[(\"output\", \"x-1\"), (\"output\", \"x+1\")])\n",
       "    >>> module(TensorDict({(\"input\", \"x\"): torch.zeros(())}, batch_size=[]))\n",
       "    TensorDict(\n",
       "        fields={\n",
       "            input: TensorDict(\n",
       "                fields={\n",
       "                    x: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                batch_size=torch.Size([]),\n",
       "                device=None,\n",
       "                is_shared=False),\n",
       "            output: TensorDict(\n",
       "                fields={\n",
       "                    x+1: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                    x-1: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                batch_size=torch.Size([]),\n",
       "                device=None,\n",
       "                is_shared=False)},\n",
       "        batch_size=torch.Size([]),\n",
       "        device=None,\n",
       "        is_shared=False)\n",
       "\n",
       "We can use TensorDictModule to populate a tensordict:\n",
       "\n",
       "Examples:\n",
       "    >>> module = TensorDictModule(lambda: torch.randn(3), in_keys=[], out_keys=[\"x\"])\n",
       "    >>> print(module(TensorDict({}, batch_size=[])))\n",
       "    TensorDict(\n",
       "        fields={\n",
       "            x: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "        batch_size=torch.Size([]),\n",
       "        device=None,\n",
       "        is_shared=False)\n",
       "\n",
       "Another feature is passing a dictionary as input keys, to control the\n",
       "dispatching of values to specific keyword arguments.\n",
       "\n",
       "Examples:\n",
       "    >>> module = TensorDictModule(lambda x, *, y: x+y,\n",
       "    ...     in_keys={'1': 'x', '2': 'y'}, out_keys=['z'], out_to_in_map=False\n",
       "    ...     )\n",
       "    >>> td = module(TensorDict({'1': torch.ones(()), '2': torch.ones(())*2}, []))\n",
       "    >>> td['z']\n",
       "    tensor(3.)\n",
       "\n",
       "If `out_to_in_map` is set to ``True``, then the `in_keys` mapping is reversed. This way,\n",
       "one can use the same input key for different keyword arguments.\n",
       "\n",
       "Examples:\n",
       "    >>> module = TensorDictModule(lambda x, *, y, z: x+y+z,\n",
       "    ...     in_keys={'x': '1', 'y': '2', z: '2'}, out_keys=['t'], out_to_in_map=True\n",
       "    ...     )\n",
       "    >>> td = module(TensorDict({'1': torch.ones(()), '2': torch.ones(())*2}, []))\n",
       "    >>> td['t']\n",
       "    tensor(5.)\n",
       "\n",
       "We can specify the method to be called within a module. Compared to using a lambda function or similar around the\n",
       "module's method, this has the advantage that the module attributes (params, buffers, submodules) will be exposed.\n",
       "\n",
       "Examples:\n",
       "    >>> from tensordict import TensorDict\n",
       "    >>> from tensordict.nn import TensorDictSequential as Seq, TensorDictModule as Mod\n",
       "    >>> from torch import nn\n",
       "    >>> import torch\n",
       "    >>>\n",
       "    >>> class MyNet(nn.Module):\n",
       "    ...     def my_func(self, tensor: torch.Tensor, *, an_integer: int):\n",
       "    ...         return tensor + an_integer\n",
       "    ...\n",
       "    >>> s = Seq(\n",
       "    ...     {\n",
       "    ...         \"a\": lambda td: td+1,\n",
       "    ...         \"b\": lambda td: td * 2,\n",
       "    ...         \"c\": Mod(MyNet(), in_keys=[\"a\"], out_keys=[\"b\"], method=\"my_func\", method_kwargs={\"an_integer\": 2}),\n",
       "    ...     }\n",
       "    ... )\n",
       "    >>> td = s(TensorDict(a=0))\n",
       "    >>> print(td)\n",
       "    >>>\n",
       "    >>> assert td[\"b\"] == 4\n",
       "\n",
       "Functional calls to a tensordict module is easy:\n",
       "\n",
       "Examples:\n",
       "    >>> import torch\n",
       "    >>> from tensordict import TensorDict\n",
       "    >>> from tensordict.nn import TensorDictModule\n",
       "    >>> td = TensorDict({\"input\": torch.randn(3, 4), \"hidden\": torch.randn(3, 8)}, [3,])\n",
       "    >>> module = torch.nn.GRUCell(4, 8)\n",
       "    >>> td_module = TensorDictModule(\n",
       "    ...    module=module, in_keys=[\"input\", \"hidden\"], out_keys=[\"output\"]\n",
       "    ... )\n",
       "    >>> params = TensorDict.from_module(td_module)\n",
       "    >>> # functional API\n",
       "    >>> with params.to_module(td_module):\n",
       "    ...     td_functional = td_module(td.clone())\n",
       "    >>> print(td_functional)\n",
       "    TensorDict(\n",
       "        fields={\n",
       "            hidden: Tensor(shape=torch.Size([3, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "            input: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "            output: Tensor(shape=torch.Size([3, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "        batch_size=torch.Size([3]),\n",
       "        device=None,\n",
       "        is_shared=False)\n",
       "\n",
       "In the stateful case:\n",
       "    >>> module = torch.nn.GRUCell(4, 8)\n",
       "    >>> td_module = TensorDictModule(\n",
       "    ...    module=module, in_keys=[\"input\", \"hidden\"], out_keys=[\"output\"]\n",
       "    ... )\n",
       "    >>> td_stateful = td_module(td.clone())\n",
       "    >>> print(td_stateful)\n",
       "    TensorDict(\n",
       "        fields={\n",
       "            hidden: Tensor(shape=torch.Size([3, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "            input: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "            output: Tensor(shape=torch.Size([3, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "        batch_size=torch.Size([3]),\n",
       "        device=None,\n",
       "        is_shared=False)\n",
       "\u001b[31mInit docstring:\u001b[39m Initialize internal Module state, shared by both nn.Module and ScriptModule."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5150c61c-f79f-4deb-a962-fbc02c7a4b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now run the true environment with the learned policy\n",
    "def env_control_policy(observation):\n",
    "    td_in = TensorDict({\"observation\": observation})\n",
    "    td_out = policy(td_in)\n",
    "    return td_out[\"action\"].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b69b0ae-b043-4167-8bb1-aa4838d880a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 1, 1, 3]' is invalid for input of size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    <function vmap.<locals>.wrapped at 0x7fc023341440>\n    in_keys=['observation']\n    out_keys=['action'].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m collector = \u001b[43mSyncDataCollector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_control_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torchrl/collectors/collectors.py:821\u001b[39m, in \u001b[36mSyncDataCollector.__init__\u001b[39m\u001b[34m(self, create_env_fn, policy, policy_factory, frames_per_batch, total_frames, device, storing_device, policy_device, env_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, return_same_td, reset_when_done, interruptor, set_truncated, use_buffers, replay_buffer, extend_buffer, trust_policy, compile_policy, cudagraph_policy, no_cuda_sync, weight_updater, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.env, \u001b[33m\"\u001b[39m\u001b[33mregister_collector\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28mself\u001b[39m.env.register_collector(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m (\u001b[38;5;28mself\u001b[39m.policy, \u001b[38;5;28mself\u001b[39m.get_weights_fn,) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_policy_and_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.policy, nn.Module):\n\u001b[32m    825\u001b[39m     \u001b[38;5;28mself\u001b[39m.policy_weights = TensorDict.from_module(\n\u001b[32m    826\u001b[39m         \u001b[38;5;28mself\u001b[39m.policy, as_module=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    827\u001b[39m     ).data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torchrl/collectors/collectors.py:200\u001b[39m, in \u001b[36mDataCollectorBase._get_policy_and_device\u001b[39m\u001b[34m(self, policy, policy_device, env_maker, env_maker_kwargs)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trust_policy:\n\u001b[32m    199\u001b[39m     env = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33menv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     policy = \u001b[43m_make_compatible_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mobservation_spec\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_maker\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_maker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43menv_maker_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv_maker_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m policy_device:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m policy, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torchrl/envs/utils.py:1603\u001b[39m, in \u001b[36m_make_compatible_policy\u001b[39m\u001b[34m(policy, observation_spec, env, fast_wrap, trust_policy, env_maker, env_maker_kwargs)\u001b[39m\n\u001b[32m   1598\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m policy_device:\n\u001b[32m   1599\u001b[39m     next_observation = tree_map(\n\u001b[32m   1600\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: x.to(policy_device), next_observation\n\u001b[32m   1601\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m output = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnext_observation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m   1606\u001b[39m     out_keys.extend(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output) - \u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36menv_control_policy\u001b[39m\u001b[34m(observation)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34menv_control_policy\u001b[39m(observation):\n\u001b[32m      3\u001b[39m     td_in = TensorDict({\u001b[33m\"\u001b[39m\u001b[33mobservation\u001b[39m\u001b[33m\"\u001b[39m: observation})\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     td_out = \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m td_out[\u001b[33m\"\u001b[39m\u001b[33maction\u001b[39m\u001b[33m\"\u001b[39m].squeeze()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1218\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1216\u001b[39m in_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1217\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1220\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1190\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSome tensors that are necessary for the module call may \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1186\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot have not been found in the input tensordict: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1188\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1192\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1193\u001b[39m ):\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1174\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1165\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(  \u001b[38;5;66;03m# type: ignore[unreachable]\u001b[39;00m\n\u001b[32m   1166\u001b[39m         tensordict._get_tuple_maybe_non_tensor(\n\u001b[32m   1167\u001b[39m             _unravel_key_to_tuple(in_key),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_keys\n\u001b[32m   1172\u001b[39m     )\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1176\u001b[39m         tensors_out = ()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/tensordict/nn/common.py:1133\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m kwargs.update(\u001b[38;5;28mself\u001b[39m.method_kwargs)\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     out = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.method)(*tensors, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/_functorch/apis.py:208\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:282\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    272\u001b[39m         func,\n\u001b[32m    273\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    278\u001b[39m         **kwargs,\n\u001b[32m    279\u001b[39m     )\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:432\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    429\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    430\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    431\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/torch-pilco/src/torch_pilco/policy_learning/rbf_layer.py:239\u001b[39m, in \u001b[36mRBFLayer.forward\u001b[39m\u001b[34m(self, observation, p_dropout)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# Compute difference from centers\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# c has size B x num_kernels x Fin\u001b[39;00m\n\u001b[32m    236\u001b[39m c = \u001b[38;5;28mself\u001b[39m.kernels_centers.expand(batch_size, \u001b[38;5;28mself\u001b[39m.num_kernels,\n\u001b[32m    237\u001b[39m                                 \u001b[38;5;28mself\u001b[39m.in_features_dim)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m diff = \u001b[43mobservation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_features_dim\u001b[49m\u001b[43m)\u001b[49m - c\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m# Apply norm function; c has size B x num_kernels\u001b[39;00m\n\u001b[32m    242\u001b[39m r = \u001b[38;5;28mself\u001b[39m.norm_function(diff)\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[3, 1, 1, 3]' is invalid for input of size 3"
     ]
    }
   ],
   "source": [
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy=env_control_policy,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=frames_per_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa07026-9c5e-44d1-b15b-9ebf3927bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now grab some data and fit the GP\n",
    "for data in collector:\n",
    "    # convert the tensordict from collector to a version\n",
    "    # suitable for dynamical model\n",
    "    replay_buffer.extend(data)\n",
    "    # Now train with all of the data seen so far:\n",
    "    # We get this by sampling from the replay buffer as many items as there are!\n",
    "    states, actions = build_pendulum_training_data(replay_buffer.sample(len(replay_buffer)))\n",
    "\n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\n",
    "        num_tasks=states.shape[1]\n",
    "    )\n",
    "    model = DynamicalModel(\n",
    "        states,\n",
    "        actions,\n",
    "        likelihood,\n",
    "    )\n",
    "\n",
    "    # Find optimal model hyperparameters\n",
    "    fit(model, likelihood, print_loss = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e500b5-bc2c-4cd8-a622-482ed0661e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_env = GPyTorchEnv(model,env,pendulum_cost,replay_buffer,batch_size=(num_particles,))\n",
    "batched_policy = torch.vmap(control_policy, in_dims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40300dd2-4290-4096-8352-d767a1e77a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = TensorDictModule(\n",
    "    batched_policy,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")\n",
    "optim = torch.optim.Adam(control_policy.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65507913-6d82-44ae-b5d0-57940057eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20_000\n",
    "pbar = tqdm.tqdm(range(N // batch_size))        # unsqueeze states\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, N)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "for _ in pbar:\n",
    "    rollout = gp_env.rollout(35, control_policy)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean(dim=0).sum()\n",
    "    traj_return.backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(control_policy.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean(dim=0).item())\n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
